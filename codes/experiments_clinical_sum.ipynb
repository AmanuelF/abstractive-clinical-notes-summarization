{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments_clinical_sum.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUEQgb1xL-ok",
        "outputId": "039bc848-e580-400e-a875-b888853b6e14"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzQkluMKMBUX",
        "outputId": "4dd79365-037b-4e59-b9fd-663dc97c90ea"
      },
      "source": [
        "%cd drive/My\\ Drive/Colab\\ Notebooks/SCH_Proposal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/SCH_Proposal'\n",
            "/content/drive/My Drive/Colab Notebooks/SCH_Proposal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF1gQku6IYfk",
        "outputId": "c2c26325-1570-4467-fb26-ec8916258737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/SCH_Proposal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mDvySQXK8Xl"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTZ8enuLYhk1"
      },
      "source": [
        "# For BART, T5, Pegasus\n",
        "#!pip3 install -q transformers==3.5.0\n",
        "!pip3 install -q transformers==4.15.0\n",
        "\n",
        "!pip3 install -q torch==1.7.0\n",
        "!pip3 install -q sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvPxXdKJguYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f72fd7-6ef8-41b4-d6d4-af4cc61bfa8a"
      },
      "source": [
        "# Checking out the GPU we have access to\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  1 10:40:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q scispacy\n",
        "!pip3 install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.3.0/en_core_sci_sm-0.3.0.tar.gz\n",
        "!pip3 install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz\n",
        "\n",
        "!python3 -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrVaW44nhGZl",
        "outputId": "37c5b2a1-59a2-4728-a468-ac2810f0be65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.0.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7 MB 536 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.0.0) (3.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.13)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.10.0.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6iPmxnVDmFy",
        "outputId": "d4a0b8ff-6ec7-408c-83f9-97c9f05662e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/SCH_Proposal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXnao9bSgTpa"
      },
      "source": [
        "!pip3 install -q jsonlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzM1_ykHaFur"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import jsonlines\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (T5Tokenizer, T5ForConditionalGeneration, \n",
        "                          BartTokenizer, BartForConditionalGeneration,\n",
        "                          PegasusTokenizer, PegasusForConditionalGeneration,\n",
        "                          ProphetNetTokenizer, ProphetNetForConditionalGeneration, ProphetNetConfig,\n",
        "                          LEDTokenizer, LEDForConditionalGeneration,\n",
        "                          BigBirdPegasusForConditionalGeneration, AutoTokenizer)\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxxwd1scQNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65c426f-165b-43f0-cb5e-6d144a00d12f"
      },
      "source": [
        "# # Setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read input args file"
      ],
      "metadata": {
        "id": "wIByg5UD_CT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"input_args.json\") as fp:\n",
        "  input_args = json.load(fp)\n",
        "fp.close()"
      ],
      "metadata": {
        "id": "7W5Mzp28_Ezy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlzvPY8U_ccK",
        "outputId": "971ad6c5-534e-423f-ada2-4dc74c6aa991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DATA_PATH': './',\n",
              " 'EPOCHS': 50,\n",
              " 'LEARNING_RATE': 0.0001,\n",
              " 'MAX_LEN': 512,\n",
              " 'SUMMARY_LEN': 210,\n",
              " 'TRAIN_BATCH_SIZE': 1,\n",
              " 'VALID_BATCH_SIZE': 1,\n",
              " 'alpha': 0.02,\n",
              " 'data_name': 'chest-x-rays',\n",
              " 'filename': 'NLMCXR_reports_ecgen_radiology_w_named_entites.jsonl',\n",
              " 'model': 'T5',\n",
              " 'model_type': 'w_named_entities',\n",
              " 'train_size': 0.8,\n",
              " 'w_named_entity': True}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xh0hGwMZ8yG"
      },
      "source": [
        "### Read and parse the pubmed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo3IEJB4PM0z"
      },
      "source": [
        "# If model training is required with two or more cost functions, this function shall return two or more dataframes for all\n",
        "# input-to-output mapping\n",
        "\n",
        "def _read_parse_data(filepath, w_named_entity=False):\n",
        "  data, final_data, final_named_entity_chain = [], [], []\n",
        "  with open(filepath) as f:\n",
        "    for line in f:\n",
        "      data.append(json.loads(line))\n",
        "  f.close()\n",
        "\n",
        "  if w_named_entity:\n",
        "    for article in data:\n",
        "      finding = \"\".join(article['finding'])\n",
        "      impression = \"\".join(article['impression']).replace('<S>', '').replace('</S>', '')\n",
        "      final_data.append([finding, impression])   # this is the source article to summary mapping dataframe\n",
        "\n",
        "      finding_entities = \" \".join(article['finding_entities'].split(' | '))\n",
        "      impression_entities = \" \".join(article['impression_entities'].split(' | '))\n",
        "      final_named_entity_chain.append([finding_entities, impression_entities])   # for mapping of finding entities and impression entities\n",
        "      \n",
        "\n",
        "    #df = pd.DataFrame(final_data, columns=['finding', 'impression', 'finding_entities'])\n",
        "    df_source_article = pd.DataFrame(final_data, columns=['finding', 'impression'])\n",
        "    df_source_article.finding = 'summarize: ' + df_source_article.finding\n",
        "\n",
        "\n",
        "    #finding_entities = df[\"finding_entities\"]\n",
        "    df_entity_chain = pd.DataFrame(final_named_entity_chain, columns=['finding_entities', 'impression_entities'])\n",
        "    df_entity_chain.finding_entities = 'summarize: ' + df_entity_chain.finding_entities\n",
        "\n",
        "    df_entity_chain.rename(columns={\"finding_entities\" : \"finding\", \"impression_entities\" : \"impression\"}, inplace=True)\n",
        "\n",
        "    return df_source_article, df_entity_chain\n",
        "\n",
        "  else:\n",
        "    for article in data:\n",
        "      impression = \"\".join(article['impression']).replace('<S>', '').replace('</S>', '')\n",
        "      finding = \"\".join(article['finding'])\n",
        "      final_data.append([finding, impression])\n",
        "\n",
        "    df_source_article = pd.DataFrame(final_data, columns=['finding', 'impression'])\n",
        "    df_source_article.finding = 'summarize: ' + df_source_article.finding\n",
        "\n",
        "    return df_source_article"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTHYRIdLBfzi"
      },
      "source": [
        "def main():\n",
        "  DATA_PATH = input_args['DATA_PATH']\n",
        "  filename = input_args['filename']\n",
        "  filepath = f\"{DATA_PATH}/{filename}\"\n",
        "\n",
        "  w_named_entity = input_args['w_named_entity']\n",
        "\n",
        "  # call to the method above\n",
        "  if w_named_entity:\n",
        "    df_source_article, df_entity_chain = _read_parse_data(filepath, w_named_entity)\n",
        "\n",
        "    return df_source_article, df_entity_chain\n",
        "\n",
        "  else:\n",
        "    df_source_article = _read_parse_data(filepath, w_named_entity)\n",
        "\n",
        "    return df_source_article\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MieU8p-SDlbV"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  w_named_entity = input_args['w_named_entity']\n",
        "  if w_named_entity:\n",
        "    df_source_article, df_entity_chain = main()\n",
        "  else:\n",
        "    df_source_article = main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FelsBOswFs5u",
        "outputId": "f05b4674-5fcb-47f9-ed7c-cb97717d94e4"
      },
      "source": [
        "df_source_article.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f2701d4-9fe1-4419-b45f-14d0ce19d238\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>finding</th>\n",
              "      <th>impression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>summarize: The heart is normal in size. The me...</td>\n",
              "      <td>No acute disease.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>summarize: None</td>\n",
              "      <td>Heart normal. Lungs clear. Upper lobe XXXX and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>summarize: Interval removal of left-sided ches...</td>\n",
              "      <td>No acute cardiopulmonary abnormality.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>summarize: None</td>\n",
              "      <td>Heart size is normal and lungs are clear. Stab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>summarize: Heart size is within normal limits....</td>\n",
              "      <td>No active disease.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f2701d4-9fe1-4419-b45f-14d0ce19d238')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f2701d4-9fe1-4419-b45f-14d0ce19d238 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f2701d4-9fe1-4419-b45f-14d0ce19d238');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             finding                                         impression\n",
              "0  summarize: The heart is normal in size. The me...                                  No acute disease.\n",
              "1                                    summarize: None  Heart normal. Lungs clear. Upper lobe XXXX and...\n",
              "2  summarize: Interval removal of left-sided ches...              No acute cardiopulmonary abnormality.\n",
              "3                                    summarize: None  Heart size is normal and lungs are clear. Stab...\n",
              "4  summarize: Heart size is within normal limits....                                 No active disease."
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if input_args['w_named_entity']:\n",
        "  print(df_entity_chain.head())"
      ],
      "metadata": {
        "id": "RHk4qiBIaQYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c152f21d-1f22-4914-84b7-9f228f5d38de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             finding                            impression\n",
            "0             summarize: opacities in right mid lung                         acute disease\n",
            "1                                        summarize:              Upper lobe XXXX emphysema\n",
            "2  summarize: Interval removal of left-sided ches...     acute cardiopulmonary abnormality\n",
            "3                                        summarize:   5 mm right midlung perform granuloma\n",
            "4  summarize: pleural effusion pneumothorax tortu...                        active disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPOJZsxHmLxD"
      },
      "source": [
        "## Select which tokenizer and model to fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJo_U_etEf7w"
      },
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "\n",
        "MAX_LEN = input_args['MAX_LEN']\n",
        "SUMMARY_LEN = input_args['SUMMARY_LEN']\n",
        "TRAIN_BATCH_SIZE = input_args['TRAIN_BATCH_SIZE']\n",
        "VALID_BATCH_SIZE = input_args['VALID_BATCH_SIZE']\n",
        "EPOCHS = input_args['EPOCHS']\n",
        "LEARNING_RATE = input_args['LEARNING_RATE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ1Jw1Q4hqEi"
      },
      "source": [
        "# Sections of config\n",
        "def _selectModel(modelName):\n",
        "  if modelName.lower() == \"t5\":\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "  elif modelName.lower() == 'bart':\n",
        "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "  elif modelName.lower() == 'pegasus':\n",
        "    tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "    model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
        "  elif modelName.lower() == 'prophetnet':\n",
        "    tokenizer = ProphetNetTokenizer.from_pretrained('microsoft/prophetnet-large-uncased-cnndm')\n",
        "    model = ProphetNetForConditionalGeneration.from_pretrained('microsoft/prophetnet-large-uncased-cnndm')\n",
        "  elif modelName.lower() == 'unilm':\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/unilm-base-cased\")\n",
        "    model = AutoModel.from_pretrained(\"microsoft/unilm-base-cased\")\n",
        "  elif modelName.lower() == 'longformer':\n",
        "    tokenizer = LEDTokenizer.from_pretrained('allenai/led-base-16384')\n",
        "    model = LEDForConditionalGeneration.from_pretrained('allenai/led-base-16384')\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  return model, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYJK-NOZFfwR"
      },
      "source": [
        "def main():\n",
        "  modelName = input_args[\"model\"]\n",
        "  model, tokenizer = _selectModel(modelName)\n",
        "\n",
        "  return model, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsCJDSFNL6VA"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  model, tokenizer = main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MLZUoBgFnuQ"
      },
      "source": [
        "### Instantiate an optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuJKj1wrFe86"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932p8NhxeNw4"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage \n",
        "# for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.impression = self.data.impression\n",
        "        self.finding = self.data.finding\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.impression)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        finding = str(self.finding[index])\n",
        "        finding = ' '.join(finding.split())\n",
        "\n",
        "        impression = str(self.impression[index])\n",
        "        impression = ' '.join(impression.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([finding], max_length= self.source_len, \n",
        "                                                  truncation=True, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([impression], max_length= self.summ_len, \n",
        "                                                  truncation=True, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70YVNa-YiSHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "196539f8-0aa8-4184-bfdd-32a945281688"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "w_named_entity = input_args['w_named_entity']\n",
        "\n",
        "train_size = input_args['train_size']\n",
        "train_dataset=df_source_article.sample(frac=train_size,random_state=42).reset_index(drop=True)\n",
        "test_dataset=df_source_article.drop(train_dataset.index).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df_source_article.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "\n",
        "\n",
        "# for the finding_entities to impression_entities mapping\n",
        "if w_named_entity:\n",
        "  train_size = input_args['train_size']\n",
        "  train_dataset_entity_chain=df_entity_chain.sample(frac=train_size,random_state=42).reset_index(drop=True)\n",
        "  test_dataset_entity_chain=df_entity_chain.drop(train_dataset_entity_chain.index).reset_index(drop=True)\n",
        "\n",
        "\n",
        "  print(\"FULL Dataset: {}\".format(df_entity_chain.shape))\n",
        "  print(\"TRAIN Dataset: {}\".format(train_dataset_entity_chain.shape))\n",
        "  print(\"TEST Dataset: {}\".format(test_dataset_entity_chain.shape))\n",
        "\n",
        "  training_set_entity_chain = CustomDataset(train_dataset_entity_chain, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "  testing_set_entity_chain = CustomDataset(test_dataset_entity_chain, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (3955, 2)\n",
            "TRAIN Dataset: (3164, 2)\n",
            "TEST Dataset: (791, 2)\n",
            "FULL Dataset: (3955, 2)\n",
            "TRAIN Dataset: (3164, 2)\n",
            "TEST Dataset: (791, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ-Spz29idNS"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# for the finding_entities to impression_entities mapping\n",
        "w_named_entity = input_args['w_named_entity']\n",
        "\n",
        "if w_named_entity:\n",
        "  training_loader_entity_chain = DataLoader(training_set_entity_chain, **train_params)\n",
        "  testing_loader_entity_chain = DataLoader(testing_set_entity_chain, **test_params)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPAR7TWmxoM"
      },
      "source": [
        "def train(epoch, w_named_entity=False, lambda_gen = 0.8, lambda_entity = 0.2):\n",
        "  model.train()\n",
        "  \n",
        "  if w_named_entity:\n",
        "    for iter, (source_data, data_entity_chain) in enumerate(zip(training_loader, training_loader_entity_chain), 0):\n",
        "      y = source_data['target_ids'].to(device, dtype = torch.long)\n",
        "      y_ids = y[:, :-1].contiguous()\n",
        "      lm_labels = y[:, 1:].clone().detach()\n",
        "      lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "      ids = source_data['source_ids'].to(device, dtype = torch.long)\n",
        "      mask = source_data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "      outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "\n",
        "      gen_loss = outputs[0]   # for the vanilla training configuration loss  ---- generative loss\n",
        "\n",
        "      y = data_entity_chain['target_ids'].to(device, dtype = torch.long)\n",
        "      y_ids = y[:, :-1].contiguous()\n",
        "      lm_labels = y[:, 1:].clone().detach()\n",
        "      lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "      ids = data_entity_chain['source_ids'].to(device, dtype = torch.long)\n",
        "      mask = data_entity_chain['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "      entity_outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)   # to grab entity loss below\n",
        "     \n",
        "      #total_loss = alpha * total_loss + alpha * outputs[0]   # total loss (i.e., with the one from the source article to summary mapping)\n",
        "      total_loss = lambda_gen * gen_loss + lambda_entity * entity_outputs[0]   # total loss (i.e., with the one from the source article to summary mapping)\n",
        "\n",
        "    \n",
        "      if iter % 500==0:\n",
        "        print(f\"Generative Loss: {gen_loss}\")\n",
        "        print(f\"Entity Loss: {entity_outputs[0]}\")\n",
        "        print(f'Epoch: {epoch}, Loss:  {total_loss.item()}')\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  else:\n",
        "    for iter, source_data in enumerate(training_loader,  0):\n",
        "      y = source_data['target_ids'].to(device, dtype = torch.long)\n",
        "      y_ids = y[:, :-1].contiguous()\n",
        "      lm_labels = y[:, 1:].clone().detach()\n",
        "      lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "      ids = source_data['source_ids'].to(device, dtype = torch.long)\n",
        "      mask = source_data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "      outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "\n",
        "      total_loss = outputs[0]\n",
        "\n",
        "      if iter % 500==0:\n",
        "          print(f'Epoch: {epoch}, Loss:  {total_loss.item()}')\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q torch==1.7.0\n",
        "!pip3 install -q git+https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjbTc_qpEvB_",
        "outputId": "78f16e94-54e0-45aa-8f96-5bbf6e8fa216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import os"
      ],
      "metadata": {
        "id": "q1SIxaMQE2fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63b-GkN0LiTh"
      },
      "source": [
        "### Call to the train method above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFAfLq7WoPqi"
      },
      "source": [
        "def main(model):\n",
        "  w_named_entity = input_args['w_named_entity']\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    train(epoch, w_named_entity)\n",
        "\n",
        "  model_name = input_args['model']\n",
        "  model_type = input_args[\"model_type\"]   # changes with type (i.e., vanilla, w_named_entities, w_named_entities_w_facts)\n",
        "  \n",
        "  data_name = input_args[\"data_name\"]\n",
        "\n",
        "  model_path = f\"{data_name}-FINAL-CHECKPTS/{model_name}\"\n",
        "  os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "  # Save entire model to a path\n",
        "  final_model_path = f\"{model_path}/{model_name}-{model_type}.pt\"\n",
        "  torch.save(model, final_model_path)\n",
        "\n",
        "\n",
        "  # Saving checkpoints\n",
        "  # model path\n",
        "  MODEL_DIRECTORY_PATH = f\"{data_name}-FINAL-CHECKPTS/{model_name}\"\n",
        "\n",
        "  model_path = f\"{MODEL_DIRECTORY_PATH}/{model_name}-{model_type}.pt\"\n",
        "  model = torch.load(model_path)\n",
        "\n",
        "  os.makedirs(f'{MODEL_DIRECTORY_PATH}/{model_name}-{model_type}-checkpoints', exist_ok=True)\n",
        "\n",
        "  model.save_pretrained(f'{MODEL_DIRECTORY_PATH}/{model_name}-{model_type}-checkpoints/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuPOoiaWMW1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec266c54-c6b6-42cc-8f9f-8670d3c141bf"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative Loss: 6.3309431076049805\n",
            "Entity Loss: 6.981210231781006\n",
            "Epoch: 0, Loss:  6.460996627807617\n",
            "Generative Loss: 11.573698997497559\n",
            "Entity Loss: 11.650496482849121\n",
            "Epoch: 0, Loss:  11.589058876037598\n",
            "Generative Loss: 5.938172817230225\n",
            "Entity Loss: 0.0\n",
            "Epoch: 0, Loss:  4.750538349151611\n",
            "Generative Loss: 10.275260925292969\n",
            "Entity Loss: 9.209420204162598\n",
            "Epoch: 0, Loss:  10.062092781066895\n",
            "Generative Loss: 9.945038795471191\n",
            "Entity Loss: 7.976722717285156\n",
            "Epoch: 0, Loss:  9.551376342773438\n",
            "Generative Loss: 10.50428295135498\n",
            "Entity Loss: 7.788739204406738\n",
            "Epoch: 0, Loss:  9.961174011230469\n",
            "Generative Loss: 11.633580207824707\n",
            "Entity Loss: 12.354945182800293\n",
            "Epoch: 0, Loss:  11.777853965759277\n",
            "Generative Loss: 7.343424320220947\n",
            "Entity Loss: 9.54072093963623\n",
            "Epoch: 1, Loss:  7.782883644104004\n",
            "Generative Loss: 5.354284286499023\n",
            "Entity Loss: 8.716141700744629\n",
            "Epoch: 1, Loss:  6.026656150817871\n",
            "Generative Loss: 8.287403106689453\n",
            "Entity Loss: 12.657877922058105\n",
            "Epoch: 1, Loss:  9.161498069763184\n",
            "Generative Loss: 10.340469360351562\n",
            "Entity Loss: 6.093351364135742\n",
            "Epoch: 1, Loss:  9.491045951843262\n",
            "Generative Loss: 9.145101547241211\n",
            "Entity Loss: 9.778206825256348\n",
            "Epoch: 1, Loss:  9.271722793579102\n",
            "Generative Loss: 8.313434600830078\n",
            "Entity Loss: 12.153054237365723\n",
            "Epoch: 1, Loss:  9.081358909606934\n",
            "Generative Loss: 9.002228736877441\n",
            "Entity Loss: 10.71366024017334\n",
            "Epoch: 1, Loss:  9.344514846801758\n",
            "Generative Loss: 10.264531135559082\n",
            "Entity Loss: 5.793861389160156\n",
            "Epoch: 2, Loss:  9.370397567749023\n",
            "Generative Loss: 6.672125339508057\n",
            "Entity Loss: 8.388566017150879\n",
            "Epoch: 2, Loss:  7.015413761138916\n",
            "Generative Loss: 7.785107135772705\n",
            "Entity Loss: 8.199777603149414\n",
            "Epoch: 2, Loss:  7.868041515350342\n",
            "Generative Loss: 6.9451141357421875\n",
            "Entity Loss: 7.052046775817871\n",
            "Epoch: 2, Loss:  6.966500759124756\n",
            "Generative Loss: 13.331171989440918\n",
            "Entity Loss: 9.049458503723145\n",
            "Epoch: 2, Loss:  12.47482967376709\n",
            "Generative Loss: 10.270028114318848\n",
            "Entity Loss: 8.613079071044922\n",
            "Epoch: 2, Loss:  9.938638687133789\n",
            "Generative Loss: 4.818180561065674\n",
            "Entity Loss: 10.492277145385742\n",
            "Epoch: 2, Loss:  5.953000068664551\n",
            "Generative Loss: 9.252867698669434\n",
            "Entity Loss: 7.656050205230713\n",
            "Epoch: 3, Loss:  8.933504104614258\n",
            "Generative Loss: 9.908655166625977\n",
            "Entity Loss: 9.266060829162598\n",
            "Epoch: 3, Loss:  9.780136108398438\n",
            "Generative Loss: 9.806095123291016\n",
            "Entity Loss: 9.216623306274414\n",
            "Epoch: 3, Loss:  9.688200950622559\n",
            "Generative Loss: 9.299534797668457\n",
            "Entity Loss: 10.286261558532715\n",
            "Epoch: 3, Loss:  9.496880531311035\n",
            "Generative Loss: 7.647493362426758\n",
            "Entity Loss: 8.463748931884766\n",
            "Epoch: 3, Loss:  7.810744762420654\n",
            "Generative Loss: 5.829426288604736\n",
            "Entity Loss: 8.464043617248535\n",
            "Epoch: 3, Loss:  6.356349945068359\n",
            "Generative Loss: 7.4775004386901855\n",
            "Entity Loss: 8.934294700622559\n",
            "Epoch: 3, Loss:  7.768859386444092\n",
            "Generative Loss: 9.306751251220703\n",
            "Entity Loss: 8.636366844177246\n",
            "Epoch: 4, Loss:  9.172674179077148\n",
            "Generative Loss: 5.922185897827148\n",
            "Entity Loss: 9.141390800476074\n",
            "Epoch: 4, Loss:  6.56602668762207\n",
            "Generative Loss: 7.896007061004639\n",
            "Entity Loss: 8.358777046203613\n",
            "Epoch: 4, Loss:  7.988561153411865\n",
            "Generative Loss: 7.852612495422363\n",
            "Entity Loss: 4.946413993835449\n",
            "Epoch: 4, Loss:  7.2713727951049805\n",
            "Generative Loss: 9.524571418762207\n",
            "Entity Loss: 8.456263542175293\n",
            "Epoch: 4, Loss:  9.310909271240234\n",
            "Generative Loss: 8.903575897216797\n",
            "Entity Loss: 9.297316551208496\n",
            "Epoch: 4, Loss:  8.982324600219727\n",
            "Generative Loss: 6.428032875061035\n",
            "Entity Loss: 10.328310012817383\n",
            "Epoch: 4, Loss:  7.2080888748168945\n",
            "Generative Loss: 7.5888848304748535\n",
            "Entity Loss: 10.533330917358398\n",
            "Epoch: 5, Loss:  8.177774429321289\n",
            "Generative Loss: 6.2227935791015625\n",
            "Entity Loss: 6.497513771057129\n",
            "Epoch: 5, Loss:  6.277737617492676\n",
            "Generative Loss: 6.999512672424316\n",
            "Entity Loss: 6.245561122894287\n",
            "Epoch: 5, Loss:  6.848722457885742\n",
            "Generative Loss: 7.445469379425049\n",
            "Entity Loss: 6.863127708435059\n",
            "Epoch: 5, Loss:  7.329001426696777\n",
            "Generative Loss: 4.633407115936279\n",
            "Entity Loss: 6.779784679412842\n",
            "Epoch: 5, Loss:  5.062682628631592\n",
            "Generative Loss: 7.86092472076416\n",
            "Entity Loss: 9.162906646728516\n",
            "Epoch: 5, Loss:  8.121320724487305\n",
            "Generative Loss: 8.067497253417969\n",
            "Entity Loss: 7.7530927658081055\n",
            "Epoch: 5, Loss:  8.004616737365723\n",
            "Generative Loss: 7.393591403961182\n",
            "Entity Loss: 8.4695463180542\n",
            "Epoch: 6, Loss:  7.6087822914123535\n",
            "Generative Loss: 8.873656272888184\n",
            "Entity Loss: 9.787325859069824\n",
            "Epoch: 6, Loss:  9.056390762329102\n",
            "Generative Loss: 7.409055233001709\n",
            "Entity Loss: 7.963047981262207\n",
            "Epoch: 6, Loss:  7.519853591918945\n",
            "Generative Loss: 5.391671657562256\n",
            "Entity Loss: 8.920199394226074\n",
            "Epoch: 6, Loss:  6.097377300262451\n",
            "Generative Loss: 8.475664138793945\n",
            "Entity Loss: 4.375914573669434\n",
            "Epoch: 6, Loss:  7.655714511871338\n",
            "Generative Loss: 8.213971138000488\n",
            "Entity Loss: 6.747823715209961\n",
            "Epoch: 6, Loss:  7.920742034912109\n",
            "Generative Loss: 6.684837818145752\n",
            "Entity Loss: 10.132814407348633\n",
            "Epoch: 6, Loss:  7.374433517456055\n",
            "Generative Loss: 7.367939472198486\n",
            "Entity Loss: 7.549590587615967\n",
            "Epoch: 7, Loss:  7.404269695281982\n",
            "Generative Loss: 6.7445292472839355\n",
            "Entity Loss: 6.858462810516357\n",
            "Epoch: 7, Loss:  6.7673163414001465\n",
            "Generative Loss: 6.212410926818848\n",
            "Entity Loss: 6.132286071777344\n",
            "Epoch: 7, Loss:  6.196385860443115\n",
            "Generative Loss: 7.0807671546936035\n",
            "Entity Loss: 9.013853073120117\n",
            "Epoch: 7, Loss:  7.467384338378906\n",
            "Generative Loss: 6.70107364654541\n",
            "Entity Loss: 8.485392570495605\n",
            "Epoch: 7, Loss:  7.0579376220703125\n",
            "Generative Loss: 9.456562042236328\n",
            "Entity Loss: 7.01777458190918\n",
            "Epoch: 7, Loss:  8.968805313110352\n",
            "Generative Loss: 7.4202141761779785\n",
            "Entity Loss: 8.648082733154297\n",
            "Epoch: 7, Loss:  7.665788173675537\n",
            "Generative Loss: 5.249446868896484\n",
            "Entity Loss: 9.812976837158203\n",
            "Epoch: 8, Loss:  6.162153244018555\n",
            "Generative Loss: 6.913653373718262\n",
            "Entity Loss: 7.17696475982666\n",
            "Epoch: 8, Loss:  6.966315746307373\n",
            "Generative Loss: 4.6211137771606445\n",
            "Entity Loss: 7.3589606285095215\n",
            "Epoch: 8, Loss:  5.168683052062988\n",
            "Generative Loss: 6.64539098739624\n",
            "Entity Loss: 11.014690399169922\n",
            "Epoch: 8, Loss:  7.519250869750977\n",
            "Generative Loss: 7.099093914031982\n",
            "Entity Loss: 8.510568618774414\n",
            "Epoch: 8, Loss:  7.3813886642456055\n",
            "Generative Loss: 6.934721946716309\n",
            "Entity Loss: 8.336358070373535\n",
            "Epoch: 8, Loss:  7.2150492668151855\n",
            "Generative Loss: 6.067038536071777\n",
            "Entity Loss: 7.922086238861084\n",
            "Epoch: 8, Loss:  6.438048362731934\n",
            "Generative Loss: 6.790379524230957\n",
            "Entity Loss: 7.599938869476318\n",
            "Epoch: 9, Loss:  6.952291488647461\n",
            "Generative Loss: 6.489720821380615\n",
            "Entity Loss: 6.186356544494629\n",
            "Epoch: 9, Loss:  6.42904806137085\n",
            "Generative Loss: 5.341522216796875\n",
            "Entity Loss: 0.0\n",
            "Epoch: 9, Loss:  4.273217678070068\n",
            "Generative Loss: 4.8681159019470215\n",
            "Entity Loss: 7.839418888092041\n",
            "Epoch: 9, Loss:  5.462376594543457\n",
            "Generative Loss: 5.945192337036133\n",
            "Entity Loss: 8.35531234741211\n",
            "Epoch: 9, Loss:  6.427216529846191\n",
            "Generative Loss: 8.984397888183594\n",
            "Entity Loss: 6.028829097747803\n",
            "Epoch: 9, Loss:  8.393284797668457\n",
            "Generative Loss: 4.9208903312683105\n",
            "Entity Loss: 4.005981922149658\n",
            "Epoch: 9, Loss:  4.737908840179443\n",
            "Generative Loss: 7.707764148712158\n",
            "Entity Loss: 5.7668352127075195\n",
            "Epoch: 10, Loss:  7.319578647613525\n",
            "Generative Loss: 7.227561950683594\n",
            "Entity Loss: 8.754294395446777\n",
            "Epoch: 10, Loss:  7.5329084396362305\n",
            "Generative Loss: 5.873660564422607\n",
            "Entity Loss: 6.9121928215026855\n",
            "Epoch: 10, Loss:  6.081367015838623\n",
            "Generative Loss: 5.969879150390625\n",
            "Entity Loss: 7.562647342681885\n",
            "Epoch: 10, Loss:  6.288432598114014\n",
            "Generative Loss: 7.021575927734375\n",
            "Entity Loss: 4.284134864807129\n",
            "Epoch: 10, Loss:  6.474087715148926\n",
            "Generative Loss: 7.053572654724121\n",
            "Entity Loss: 5.663954734802246\n",
            "Epoch: 10, Loss:  6.775649070739746\n",
            "Generative Loss: 5.781107425689697\n",
            "Entity Loss: 8.120935440063477\n",
            "Epoch: 10, Loss:  6.249073028564453\n",
            "Generative Loss: 6.599016189575195\n",
            "Entity Loss: 6.0245890617370605\n",
            "Epoch: 11, Loss:  6.484130859375\n",
            "Generative Loss: 7.135599613189697\n",
            "Entity Loss: 4.960159778594971\n",
            "Epoch: 11, Loss:  6.700511932373047\n",
            "Generative Loss: 3.8669016361236572\n",
            "Entity Loss: 5.2390666007995605\n",
            "Epoch: 11, Loss:  4.141334533691406\n",
            "Generative Loss: 8.094432830810547\n",
            "Entity Loss: 7.279290676116943\n",
            "Epoch: 11, Loss:  7.9314045906066895\n",
            "Generative Loss: 8.77562141418457\n",
            "Entity Loss: 6.017177581787109\n",
            "Epoch: 11, Loss:  8.223933219909668\n",
            "Generative Loss: 4.490360260009766\n",
            "Entity Loss: 9.620162010192871\n",
            "Epoch: 11, Loss:  5.516320705413818\n",
            "Generative Loss: 6.26794958114624\n",
            "Entity Loss: 6.433572292327881\n",
            "Epoch: 11, Loss:  6.301074504852295\n",
            "Generative Loss: 7.461693286895752\n",
            "Entity Loss: 8.996475219726562\n",
            "Epoch: 12, Loss:  7.768649578094482\n",
            "Generative Loss: 5.117249011993408\n",
            "Entity Loss: 5.648200035095215\n",
            "Epoch: 12, Loss:  5.2234392166137695\n",
            "Generative Loss: 7.467221736907959\n",
            "Entity Loss: 8.985267639160156\n",
            "Epoch: 12, Loss:  7.770831108093262\n",
            "Generative Loss: 6.6423659324646\n",
            "Entity Loss: 6.834501266479492\n",
            "Epoch: 12, Loss:  6.680793285369873\n",
            "Generative Loss: 6.753517150878906\n",
            "Entity Loss: 7.13412618637085\n",
            "Epoch: 12, Loss:  6.829639434814453\n",
            "Generative Loss: 5.678260803222656\n",
            "Entity Loss: 6.838517665863037\n",
            "Epoch: 12, Loss:  5.910312175750732\n",
            "Generative Loss: 4.297288417816162\n",
            "Entity Loss: 5.517777442932129\n",
            "Epoch: 12, Loss:  4.541386127471924\n",
            "Generative Loss: 6.055266857147217\n",
            "Entity Loss: 4.5968241691589355\n",
            "Epoch: 13, Loss:  5.763578414916992\n",
            "Generative Loss: 6.607304096221924\n",
            "Entity Loss: 9.941534042358398\n",
            "Epoch: 13, Loss:  7.274150371551514\n",
            "Generative Loss: 6.54712438583374\n",
            "Entity Loss: 4.789041996002197\n",
            "Epoch: 13, Loss:  6.195508003234863\n",
            "Generative Loss: 6.227038383483887\n",
            "Entity Loss: 7.185671329498291\n",
            "Epoch: 13, Loss:  6.418765068054199\n",
            "Generative Loss: 5.3443803787231445\n",
            "Entity Loss: 5.455690383911133\n",
            "Epoch: 13, Loss:  5.366642951965332\n",
            "Generative Loss: 7.057880878448486\n",
            "Entity Loss: 7.3398661613464355\n",
            "Epoch: 13, Loss:  7.1142778396606445\n",
            "Generative Loss: 7.730309009552002\n",
            "Entity Loss: 8.858086585998535\n",
            "Epoch: 13, Loss:  7.955864906311035\n",
            "Generative Loss: 2.9810173511505127\n",
            "Entity Loss: 8.28172779083252\n",
            "Epoch: 14, Loss:  4.041159629821777\n",
            "Generative Loss: 4.664159774780273\n",
            "Entity Loss: 8.370969772338867\n",
            "Epoch: 14, Loss:  5.405521869659424\n",
            "Generative Loss: 7.560262680053711\n",
            "Entity Loss: 9.977156639099121\n",
            "Epoch: 14, Loss:  8.043641090393066\n",
            "Generative Loss: 8.402382850646973\n",
            "Entity Loss: 5.988752365112305\n",
            "Epoch: 14, Loss:  7.919656753540039\n",
            "Generative Loss: 5.4746809005737305\n",
            "Entity Loss: 3.648158311843872\n",
            "Epoch: 14, Loss:  5.109376907348633\n",
            "Generative Loss: 6.677358150482178\n",
            "Entity Loss: 5.997825622558594\n",
            "Epoch: 14, Loss:  6.541451454162598\n",
            "Generative Loss: 6.2700886726379395\n",
            "Entity Loss: 5.245855808258057\n",
            "Epoch: 14, Loss:  6.065241813659668\n",
            "Generative Loss: 5.047549724578857\n",
            "Entity Loss: 0.0\n",
            "Epoch: 15, Loss:  4.038039684295654\n",
            "Generative Loss: 5.785808563232422\n",
            "Entity Loss: 0.0\n",
            "Epoch: 15, Loss:  4.6286468505859375\n",
            "Generative Loss: 4.872940540313721\n",
            "Entity Loss: 8.72939682006836\n",
            "Epoch: 15, Loss:  5.644231796264648\n",
            "Generative Loss: 5.02529764175415\n",
            "Entity Loss: 7.949007987976074\n",
            "Epoch: 15, Loss:  5.610040187835693\n",
            "Generative Loss: 4.601456165313721\n",
            "Entity Loss: 6.433496952056885\n",
            "Epoch: 15, Loss:  4.967864513397217\n",
            "Generative Loss: 6.999297618865967\n",
            "Entity Loss: 7.570939540863037\n",
            "Epoch: 15, Loss:  7.113626003265381\n",
            "Generative Loss: 4.949169635772705\n",
            "Entity Loss: 6.999544143676758\n",
            "Epoch: 15, Loss:  5.3592448234558105\n",
            "Generative Loss: 5.548398971557617\n",
            "Entity Loss: 6.817516803741455\n",
            "Epoch: 16, Loss:  5.802222728729248\n",
            "Generative Loss: 5.722789764404297\n",
            "Entity Loss: 5.350221633911133\n",
            "Epoch: 16, Loss:  5.648276329040527\n",
            "Generative Loss: 4.784396171569824\n",
            "Entity Loss: 6.765874862670898\n",
            "Epoch: 16, Loss:  5.180692195892334\n",
            "Generative Loss: 4.3301472663879395\n",
            "Entity Loss: 8.426698684692383\n",
            "Epoch: 16, Loss:  5.1494574546813965\n",
            "Generative Loss: 4.581601619720459\n",
            "Entity Loss: 6.16628360748291\n",
            "Epoch: 16, Loss:  4.898538112640381\n",
            "Generative Loss: 6.750061988830566\n",
            "Entity Loss: 5.809591770172119\n",
            "Epoch: 16, Loss:  6.561967849731445\n",
            "Generative Loss: 5.526576519012451\n",
            "Entity Loss: 6.661306381225586\n",
            "Epoch: 16, Loss:  5.753522872924805\n",
            "Generative Loss: 5.267113208770752\n",
            "Entity Loss: 0.0\n",
            "Epoch: 17, Loss:  4.213690757751465\n",
            "Generative Loss: 8.972426414489746\n",
            "Entity Loss: 8.65439224243164\n",
            "Epoch: 17, Loss:  8.908820152282715\n",
            "Generative Loss: 5.681103706359863\n",
            "Entity Loss: 0.0\n",
            "Epoch: 17, Loss:  4.5448832511901855\n",
            "Generative Loss: 4.402995586395264\n",
            "Entity Loss: 4.508594036102295\n",
            "Epoch: 17, Loss:  4.424115180969238\n",
            "Generative Loss: 5.458684921264648\n",
            "Entity Loss: 6.200942516326904\n",
            "Epoch: 17, Loss:  5.6071367263793945\n",
            "Generative Loss: 5.190711498260498\n",
            "Entity Loss: 9.134066581726074\n",
            "Epoch: 17, Loss:  5.979382514953613\n",
            "Generative Loss: 4.897158145904541\n",
            "Entity Loss: 7.558396816253662\n",
            "Epoch: 17, Loss:  5.42940616607666\n",
            "Generative Loss: 5.361420631408691\n",
            "Entity Loss: 5.35471248626709\n",
            "Epoch: 18, Loss:  5.360078811645508\n",
            "Generative Loss: 4.1541948318481445\n",
            "Entity Loss: 5.0066094398498535\n",
            "Epoch: 18, Loss:  4.32467794418335\n",
            "Generative Loss: 6.148786544799805\n",
            "Entity Loss: 7.2077956199646\n",
            "Epoch: 18, Loss:  6.360588550567627\n",
            "Generative Loss: 4.052865505218506\n",
            "Entity Loss: 6.385717868804932\n",
            "Epoch: 18, Loss:  4.519435882568359\n",
            "Generative Loss: 4.408655643463135\n",
            "Entity Loss: 6.885963439941406\n",
            "Epoch: 18, Loss:  4.904117584228516\n",
            "Generative Loss: 5.177354335784912\n",
            "Entity Loss: 5.786998271942139\n",
            "Epoch: 18, Loss:  5.299283027648926\n",
            "Generative Loss: 5.7711687088012695\n",
            "Entity Loss: 5.036623954772949\n",
            "Epoch: 18, Loss:  5.624259948730469\n",
            "Generative Loss: 4.513070106506348\n",
            "Entity Loss: 7.088753700256348\n",
            "Epoch: 19, Loss:  5.028206825256348\n",
            "Generative Loss: 4.263853073120117\n",
            "Entity Loss: 8.17275333404541\n",
            "Epoch: 19, Loss:  5.045633316040039\n",
            "Generative Loss: 5.884761333465576\n",
            "Entity Loss: 6.724771022796631\n",
            "Epoch: 19, Loss:  6.052762985229492\n",
            "Generative Loss: 4.323018550872803\n",
            "Entity Loss: 4.227276802062988\n",
            "Epoch: 19, Loss:  4.30387020111084\n",
            "Generative Loss: 4.340124607086182\n",
            "Entity Loss: 5.104748725891113\n",
            "Epoch: 19, Loss:  4.493049621582031\n",
            "Generative Loss: 3.383244752883911\n",
            "Entity Loss: 4.185542106628418\n",
            "Epoch: 19, Loss:  3.5437042713165283\n",
            "Generative Loss: 7.385803699493408\n",
            "Entity Loss: 5.390601634979248\n",
            "Epoch: 19, Loss:  6.9867634773254395\n",
            "Generative Loss: 9.411028861999512\n",
            "Entity Loss: 6.650811672210693\n",
            "Epoch: 20, Loss:  8.858985900878906\n",
            "Generative Loss: 4.813945770263672\n",
            "Entity Loss: 5.374761581420898\n",
            "Epoch: 20, Loss:  4.926109313964844\n",
            "Generative Loss: 5.474594593048096\n",
            "Entity Loss: 6.134731292724609\n",
            "Epoch: 20, Loss:  5.606622219085693\n",
            "Generative Loss: 3.3864316940307617\n",
            "Entity Loss: 4.370977878570557\n",
            "Epoch: 20, Loss:  3.583340883255005\n",
            "Generative Loss: 3.8413474559783936\n",
            "Entity Loss: 7.655791282653809\n",
            "Epoch: 20, Loss:  4.604236125946045\n",
            "Generative Loss: 5.288894176483154\n",
            "Entity Loss: 5.862720489501953\n",
            "Epoch: 20, Loss:  5.403659343719482\n",
            "Generative Loss: 2.200974225997925\n",
            "Entity Loss: 4.983902931213379\n",
            "Epoch: 20, Loss:  2.7575600147247314\n",
            "Generative Loss: 4.3561692237854\n",
            "Entity Loss: 4.739337921142578\n",
            "Epoch: 21, Loss:  4.432803153991699\n",
            "Generative Loss: 4.455428123474121\n",
            "Entity Loss: 2.664144515991211\n",
            "Epoch: 21, Loss:  4.097171306610107\n",
            "Generative Loss: 4.8383893966674805\n",
            "Entity Loss: 0.0\n",
            "Epoch: 21, Loss:  3.8707115650177\n",
            "Generative Loss: 7.5307297706604\n",
            "Entity Loss: 5.21336555480957\n",
            "Epoch: 21, Loss:  7.067256927490234\n",
            "Generative Loss: 6.544639587402344\n",
            "Entity Loss: 5.063390731811523\n",
            "Epoch: 21, Loss:  6.248389720916748\n",
            "Generative Loss: 4.583423614501953\n",
            "Entity Loss: 7.168452262878418\n",
            "Epoch: 21, Loss:  5.100429534912109\n",
            "Generative Loss: 4.439716815948486\n",
            "Entity Loss: 6.471669673919678\n",
            "Epoch: 21, Loss:  4.846107482910156\n",
            "Generative Loss: 4.559321880340576\n",
            "Entity Loss: 5.027014255523682\n",
            "Epoch: 22, Loss:  4.652860641479492\n",
            "Generative Loss: 5.195291519165039\n",
            "Entity Loss: 8.006487846374512\n",
            "Epoch: 22, Loss:  5.75753116607666\n",
            "Generative Loss: 4.1763153076171875\n",
            "Entity Loss: 4.347665309906006\n",
            "Epoch: 22, Loss:  4.210585594177246\n",
            "Generative Loss: 4.230952739715576\n",
            "Entity Loss: 6.118916988372803\n",
            "Epoch: 22, Loss:  4.608545780181885\n",
            "Generative Loss: 3.9154856204986572\n",
            "Entity Loss: 6.680555820465088\n",
            "Epoch: 22, Loss:  4.468499660491943\n",
            "Generative Loss: 4.409669876098633\n",
            "Entity Loss: 6.110929012298584\n",
            "Epoch: 22, Loss:  4.749921798706055\n",
            "Generative Loss: 5.92108154296875\n",
            "Entity Loss: 5.331940174102783\n",
            "Epoch: 22, Loss:  5.803253650665283\n",
            "Generative Loss: 3.7542386054992676\n",
            "Entity Loss: 5.070273399353027\n",
            "Epoch: 23, Loss:  4.0174455642700195\n",
            "Generative Loss: 4.696053981781006\n",
            "Entity Loss: 0.0\n",
            "Epoch: 23, Loss:  3.756843328475952\n",
            "Generative Loss: 2.9301748275756836\n",
            "Entity Loss: 5.3516082763671875\n",
            "Epoch: 23, Loss:  3.414461612701416\n",
            "Generative Loss: 3.315997362136841\n",
            "Entity Loss: 8.8175630569458\n",
            "Epoch: 23, Loss:  4.4163103103637695\n",
            "Generative Loss: 4.923641204833984\n",
            "Entity Loss: 5.254823207855225\n",
            "Epoch: 23, Loss:  4.989877700805664\n",
            "Generative Loss: 4.155945777893066\n",
            "Entity Loss: 5.566804885864258\n",
            "Epoch: 23, Loss:  4.438117504119873\n",
            "Generative Loss: 4.679809093475342\n",
            "Entity Loss: 5.732151985168457\n",
            "Epoch: 23, Loss:  4.890277862548828\n",
            "Generative Loss: 3.8006649017333984\n",
            "Entity Loss: 8.182299613952637\n",
            "Epoch: 24, Loss:  4.676991939544678\n",
            "Generative Loss: 4.9930267333984375\n",
            "Entity Loss: 4.541837215423584\n",
            "Epoch: 24, Loss:  4.902789115905762\n",
            "Generative Loss: 3.2968788146972656\n",
            "Entity Loss: 5.885672092437744\n",
            "Epoch: 24, Loss:  3.8146376609802246\n",
            "Generative Loss: 6.689724445343018\n",
            "Entity Loss: 4.943626880645752\n",
            "Epoch: 24, Loss:  6.3405046463012695\n",
            "Generative Loss: 4.703378677368164\n",
            "Entity Loss: 6.756811141967773\n",
            "Epoch: 24, Loss:  5.114065170288086\n",
            "Generative Loss: 4.921401500701904\n",
            "Entity Loss: 8.749061584472656\n",
            "Epoch: 24, Loss:  5.686933517456055\n",
            "Generative Loss: 4.766483306884766\n",
            "Entity Loss: 3.270174980163574\n",
            "Epoch: 24, Loss:  4.467221736907959\n",
            "Generative Loss: 5.558870792388916\n",
            "Entity Loss: 6.010244369506836\n",
            "Epoch: 25, Loss:  5.649145603179932\n",
            "Generative Loss: 5.315073490142822\n",
            "Entity Loss: 3.2827963829040527\n",
            "Epoch: 25, Loss:  4.908618450164795\n",
            "Generative Loss: 3.8217179775238037\n",
            "Entity Loss: 5.234579563140869\n",
            "Epoch: 25, Loss:  4.10429048538208\n",
            "Generative Loss: 5.884827136993408\n",
            "Entity Loss: 5.459621429443359\n",
            "Epoch: 25, Loss:  5.79978609085083\n",
            "Generative Loss: 4.623809337615967\n",
            "Entity Loss: 4.259552955627441\n",
            "Epoch: 25, Loss:  4.550958156585693\n",
            "Generative Loss: 3.659445285797119\n",
            "Entity Loss: 9.211739540100098\n",
            "Epoch: 25, Loss:  4.769904136657715\n",
            "Generative Loss: 4.18388557434082\n",
            "Entity Loss: 3.033804178237915\n",
            "Epoch: 25, Loss:  3.953869342803955\n",
            "Generative Loss: 5.621298313140869\n",
            "Entity Loss: 7.3361005783081055\n",
            "Epoch: 26, Loss:  5.964259147644043\n",
            "Generative Loss: 5.271072864532471\n",
            "Entity Loss: 5.248295783996582\n",
            "Epoch: 26, Loss:  5.266517639160156\n",
            "Generative Loss: 5.6256232261657715\n",
            "Entity Loss: 5.488018989562988\n",
            "Epoch: 26, Loss:  5.598102569580078\n",
            "Generative Loss: 4.889072895050049\n",
            "Entity Loss: 5.499063014984131\n",
            "Epoch: 26, Loss:  5.01107120513916\n",
            "Generative Loss: 3.787553548812866\n",
            "Entity Loss: 6.245187759399414\n",
            "Epoch: 26, Loss:  4.279080390930176\n",
            "Generative Loss: 6.902740478515625\n",
            "Entity Loss: 6.640018939971924\n",
            "Epoch: 26, Loss:  6.850196361541748\n",
            "Generative Loss: 3.4257302284240723\n",
            "Entity Loss: 8.359216690063477\n",
            "Epoch: 26, Loss:  4.4124274253845215\n",
            "Generative Loss: 5.140334129333496\n",
            "Entity Loss: 5.694864273071289\n",
            "Epoch: 27, Loss:  5.251240253448486\n",
            "Generative Loss: 5.1104936599731445\n",
            "Entity Loss: 2.8744139671325684\n",
            "Epoch: 27, Loss:  4.663278102874756\n",
            "Generative Loss: 4.4599714279174805\n",
            "Entity Loss: 5.620510578155518\n",
            "Epoch: 27, Loss:  4.692079544067383\n",
            "Generative Loss: 3.3491499423980713\n",
            "Entity Loss: 2.4067208766937256\n",
            "Epoch: 27, Loss:  3.1606643199920654\n",
            "Generative Loss: 4.497500419616699\n",
            "Entity Loss: 6.317631721496582\n",
            "Epoch: 27, Loss:  4.8615264892578125\n",
            "Generative Loss: 5.135858535766602\n",
            "Entity Loss: 6.820516109466553\n",
            "Epoch: 27, Loss:  5.472790241241455\n",
            "Generative Loss: 3.6275761127471924\n",
            "Entity Loss: 3.2599754333496094\n",
            "Epoch: 27, Loss:  3.554056167602539\n",
            "Generative Loss: 4.433637619018555\n",
            "Entity Loss: 0.0\n",
            "Epoch: 28, Loss:  3.546910047531128\n",
            "Generative Loss: 3.697709798812866\n",
            "Entity Loss: 3.5464682579040527\n",
            "Epoch: 28, Loss:  3.667461395263672\n",
            "Generative Loss: 4.1798295974731445\n",
            "Entity Loss: 3.7766335010528564\n",
            "Epoch: 28, Loss:  4.0991902351379395\n",
            "Generative Loss: 3.3579914569854736\n",
            "Entity Loss: 5.546939373016357\n",
            "Epoch: 28, Loss:  3.795781135559082\n",
            "Generative Loss: 3.5005319118499756\n",
            "Entity Loss: 5.20842170715332\n",
            "Epoch: 28, Loss:  3.8421099185943604\n",
            "Generative Loss: 4.909698963165283\n",
            "Entity Loss: 6.516368389129639\n",
            "Epoch: 28, Loss:  5.231032848358154\n",
            "Generative Loss: 6.1469197273254395\n",
            "Entity Loss: 5.885970592498779\n",
            "Epoch: 28, Loss:  6.094729900360107\n",
            "Generative Loss: 2.6962080001831055\n",
            "Entity Loss: 7.225366115570068\n",
            "Epoch: 29, Loss:  3.6020398139953613\n",
            "Generative Loss: 2.809720754623413\n",
            "Entity Loss: 3.0863399505615234\n",
            "Epoch: 29, Loss:  2.8650448322296143\n",
            "Generative Loss: 1.842603325843811\n",
            "Entity Loss: 5.333451271057129\n",
            "Epoch: 29, Loss:  2.5407729148864746\n",
            "Generative Loss: 4.89877462387085\n",
            "Entity Loss: 3.965627908706665\n",
            "Epoch: 29, Loss:  4.7121453285217285\n",
            "Generative Loss: 4.3619208335876465\n",
            "Entity Loss: 5.4796905517578125\n",
            "Epoch: 29, Loss:  4.585474967956543\n",
            "Generative Loss: 2.6738295555114746\n",
            "Entity Loss: 6.706462860107422\n",
            "Epoch: 29, Loss:  3.480356216430664\n",
            "Generative Loss: 3.2422163486480713\n",
            "Entity Loss: 2.930739641189575\n",
            "Epoch: 29, Loss:  3.1799211502075195\n",
            "Generative Loss: 3.8133544921875\n",
            "Entity Loss: 5.940511226654053\n",
            "Epoch: 30, Loss:  4.238785743713379\n",
            "Generative Loss: 3.4502832889556885\n",
            "Entity Loss: 5.299328804016113\n",
            "Epoch: 30, Loss:  3.8200926780700684\n",
            "Generative Loss: 4.110174179077148\n",
            "Entity Loss: 5.298935890197754\n",
            "Epoch: 30, Loss:  4.347926616668701\n",
            "Generative Loss: 5.183854579925537\n",
            "Entity Loss: 3.154148578643799\n",
            "Epoch: 30, Loss:  4.777913570404053\n",
            "Generative Loss: 4.455025672912598\n",
            "Entity Loss: 6.2963433265686035\n",
            "Epoch: 30, Loss:  4.823289394378662\n",
            "Generative Loss: 3.7917213439941406\n",
            "Entity Loss: 3.4625213146209717\n",
            "Epoch: 30, Loss:  3.725881576538086\n",
            "Generative Loss: 2.832179546356201\n",
            "Entity Loss: 0.0\n",
            "Epoch: 30, Loss:  2.2657437324523926\n",
            "Generative Loss: 4.44948148727417\n",
            "Entity Loss: 5.790178298950195\n",
            "Epoch: 31, Loss:  4.717620849609375\n",
            "Generative Loss: 2.926703929901123\n",
            "Entity Loss: 0.0\n",
            "Epoch: 31, Loss:  2.3413631916046143\n",
            "Generative Loss: 3.1747424602508545\n",
            "Entity Loss: 4.165014266967773\n",
            "Epoch: 31, Loss:  3.3727967739105225\n",
            "Generative Loss: 5.549187660217285\n",
            "Entity Loss: 2.8679559230804443\n",
            "Epoch: 31, Loss:  5.012941360473633\n",
            "Generative Loss: 5.055004596710205\n",
            "Entity Loss: 4.785000324249268\n",
            "Epoch: 31, Loss:  5.001004219055176\n",
            "Generative Loss: 2.3733952045440674\n",
            "Entity Loss: 3.5733509063720703\n",
            "Epoch: 31, Loss:  2.613386392593384\n",
            "Generative Loss: 3.3790295124053955\n",
            "Entity Loss: 2.9758615493774414\n",
            "Epoch: 31, Loss:  3.298396110534668\n",
            "Generative Loss: 3.663630247116089\n",
            "Entity Loss: 3.8084194660186768\n",
            "Epoch: 32, Loss:  3.6925880908966064\n",
            "Generative Loss: 4.531135082244873\n",
            "Entity Loss: 3.234487771987915\n",
            "Epoch: 32, Loss:  4.271805763244629\n",
            "Generative Loss: 2.6162526607513428\n",
            "Entity Loss: 4.906858921051025\n",
            "Epoch: 32, Loss:  3.074373960494995\n",
            "Generative Loss: 1.8013616800308228\n",
            "Entity Loss: 5.856961727142334\n",
            "Epoch: 32, Loss:  2.6124815940856934\n",
            "Generative Loss: 5.1190643310546875\n",
            "Entity Loss: 6.0027923583984375\n",
            "Epoch: 32, Loss:  5.295810222625732\n",
            "Generative Loss: 3.119990110397339\n",
            "Entity Loss: 4.338465690612793\n",
            "Epoch: 32, Loss:  3.363685369491577\n",
            "Generative Loss: 4.9740309715271\n",
            "Entity Loss: 5.7983856201171875\n",
            "Epoch: 32, Loss:  5.138902187347412\n",
            "Generative Loss: 5.397375583648682\n",
            "Entity Loss: 5.3459062576293945\n",
            "Epoch: 33, Loss:  5.387082099914551\n",
            "Generative Loss: 3.8827435970306396\n",
            "Entity Loss: 3.4508659839630127\n",
            "Epoch: 33, Loss:  3.79636812210083\n",
            "Generative Loss: 5.1864728927612305\n",
            "Entity Loss: 5.995559215545654\n",
            "Epoch: 33, Loss:  5.34829044342041\n",
            "Generative Loss: 3.9078211784362793\n",
            "Entity Loss: 5.132557392120361\n",
            "Epoch: 33, Loss:  4.152768611907959\n",
            "Generative Loss: 4.834425926208496\n",
            "Entity Loss: 6.563864707946777\n",
            "Epoch: 33, Loss:  5.180314064025879\n",
            "Generative Loss: 4.22487211227417\n",
            "Entity Loss: 2.211538314819336\n",
            "Epoch: 33, Loss:  3.8222055435180664\n",
            "Generative Loss: 2.6763246059417725\n",
            "Entity Loss: 3.6826467514038086\n",
            "Epoch: 33, Loss:  2.877588987350464\n",
            "Generative Loss: 5.246859073638916\n",
            "Entity Loss: 3.7212555408477783\n",
            "Epoch: 34, Loss:  4.941738605499268\n",
            "Generative Loss: 3.9334354400634766\n",
            "Entity Loss: 4.063662052154541\n",
            "Epoch: 34, Loss:  3.9594807624816895\n",
            "Generative Loss: 3.71413254737854\n",
            "Entity Loss: 6.352025985717773\n",
            "Epoch: 34, Loss:  4.241711139678955\n",
            "Generative Loss: 2.842313289642334\n",
            "Entity Loss: 6.5576324462890625\n",
            "Epoch: 34, Loss:  3.5853772163391113\n",
            "Generative Loss: 4.958239555358887\n",
            "Entity Loss: 5.210594654083252\n",
            "Epoch: 34, Loss:  5.0087103843688965\n",
            "Generative Loss: 2.8999178409576416\n",
            "Entity Loss: 5.0279316902160645\n",
            "Epoch: 34, Loss:  3.3255207538604736\n",
            "Generative Loss: 2.4647021293640137\n",
            "Entity Loss: 6.325845241546631\n",
            "Epoch: 34, Loss:  3.2369308471679688\n",
            "Generative Loss: 4.530557632446289\n",
            "Entity Loss: 4.612982273101807\n",
            "Epoch: 35, Loss:  4.5470428466796875\n",
            "Generative Loss: 2.5293054580688477\n",
            "Entity Loss: 6.918032169342041\n",
            "Epoch: 35, Loss:  3.407050848007202\n",
            "Generative Loss: 4.487399101257324\n",
            "Entity Loss: 6.1163554191589355\n",
            "Epoch: 35, Loss:  4.813190460205078\n",
            "Generative Loss: 3.0810739994049072\n",
            "Entity Loss: 6.440123081207275\n",
            "Epoch: 35, Loss:  3.7528839111328125\n",
            "Generative Loss: 3.360884666442871\n",
            "Entity Loss: 6.773385524749756\n",
            "Epoch: 35, Loss:  4.043385028839111\n",
            "Generative Loss: 2.405090093612671\n",
            "Entity Loss: 4.302403926849365\n",
            "Epoch: 35, Loss:  2.784553050994873\n",
            "Generative Loss: 2.6736996173858643\n",
            "Entity Loss: 5.558426380157471\n",
            "Epoch: 35, Loss:  3.2506449222564697\n",
            "Generative Loss: 2.3399882316589355\n",
            "Entity Loss: 2.9052255153656006\n",
            "Epoch: 36, Loss:  2.453035593032837\n",
            "Generative Loss: 2.6960010528564453\n",
            "Entity Loss: 3.8133296966552734\n",
            "Epoch: 36, Loss:  2.919466972351074\n",
            "Generative Loss: 2.575505495071411\n",
            "Entity Loss: 5.387960910797119\n",
            "Epoch: 36, Loss:  3.1379966735839844\n",
            "Generative Loss: 6.507052898406982\n",
            "Entity Loss: 3.037424087524414\n",
            "Epoch: 36, Loss:  5.813127040863037\n",
            "Generative Loss: 2.5384035110473633\n",
            "Entity Loss: 5.337451457977295\n",
            "Epoch: 36, Loss:  3.0982131958007812\n",
            "Generative Loss: 1.9855128526687622\n",
            "Entity Loss: 2.4794201850891113\n",
            "Epoch: 36, Loss:  2.084294319152832\n",
            "Generative Loss: 3.63042950630188\n",
            "Entity Loss: 5.091268539428711\n",
            "Epoch: 36, Loss:  3.9225974082946777\n",
            "Generative Loss: 2.037554979324341\n",
            "Entity Loss: 3.494753360748291\n",
            "Epoch: 37, Loss:  2.3289947509765625\n",
            "Generative Loss: 3.5342586040496826\n",
            "Entity Loss: 4.544801712036133\n",
            "Epoch: 37, Loss:  3.7363672256469727\n",
            "Generative Loss: 2.314990997314453\n",
            "Entity Loss: 2.4181368350982666\n",
            "Epoch: 37, Loss:  2.335620164871216\n",
            "Generative Loss: 5.505488872528076\n",
            "Entity Loss: 5.380768775939941\n",
            "Epoch: 37, Loss:  5.4805450439453125\n",
            "Generative Loss: 6.677103519439697\n",
            "Entity Loss: 7.172091484069824\n",
            "Epoch: 37, Loss:  6.776101112365723\n",
            "Generative Loss: 3.074406862258911\n",
            "Entity Loss: 3.3842077255249023\n",
            "Epoch: 37, Loss:  3.136367082595825\n",
            "Generative Loss: 1.225993037223816\n",
            "Entity Loss: 3.9549946784973145\n",
            "Epoch: 37, Loss:  1.7717933654785156\n",
            "Generative Loss: 5.998148441314697\n",
            "Entity Loss: 1.9555937051773071\n",
            "Epoch: 38, Loss:  5.189637184143066\n",
            "Generative Loss: 1.4528751373291016\n",
            "Entity Loss: 6.6119585037231445\n",
            "Epoch: 38, Loss:  2.484691858291626\n",
            "Generative Loss: 5.132350444793701\n",
            "Entity Loss: 7.392772674560547\n",
            "Epoch: 38, Loss:  5.584434986114502\n",
            "Generative Loss: 6.447724342346191\n",
            "Entity Loss: 6.654826641082764\n",
            "Epoch: 38, Loss:  6.489145278930664\n",
            "Generative Loss: 4.920043468475342\n",
            "Entity Loss: 5.360080242156982\n",
            "Epoch: 38, Loss:  5.008050918579102\n",
            "Generative Loss: 5.478827953338623\n",
            "Entity Loss: 1.5627037286758423\n",
            "Epoch: 38, Loss:  4.695602893829346\n",
            "Generative Loss: 4.428261756896973\n",
            "Entity Loss: 2.073089599609375\n",
            "Epoch: 38, Loss:  3.9572274684906006\n",
            "Generative Loss: 3.474313735961914\n",
            "Entity Loss: 4.931183815002441\n",
            "Epoch: 39, Loss:  3.765687942504883\n",
            "Generative Loss: 5.466496467590332\n",
            "Entity Loss: 2.575533390045166\n",
            "Epoch: 39, Loss:  4.888303756713867\n",
            "Generative Loss: 5.3239264488220215\n",
            "Entity Loss: 0.0\n",
            "Epoch: 39, Loss:  4.259141445159912\n",
            "Generative Loss: 2.4434876441955566\n",
            "Entity Loss: 2.5338499546051025\n",
            "Epoch: 39, Loss:  2.4615602493286133\n",
            "Generative Loss: 1.7979495525360107\n",
            "Entity Loss: 5.926447868347168\n",
            "Epoch: 39, Loss:  2.6236491203308105\n",
            "Generative Loss: 2.3975064754486084\n",
            "Entity Loss: 5.78938102722168\n",
            "Epoch: 39, Loss:  3.0758814811706543\n",
            "Generative Loss: 5.859145641326904\n",
            "Entity Loss: 4.539060592651367\n",
            "Epoch: 39, Loss:  5.595128536224365\n",
            "Generative Loss: 3.0502960681915283\n",
            "Entity Loss: 3.107064723968506\n",
            "Epoch: 40, Loss:  3.061649799346924\n",
            "Generative Loss: 3.954793691635132\n",
            "Entity Loss: 6.581820964813232\n",
            "Epoch: 40, Loss:  4.480199337005615\n",
            "Generative Loss: 2.551896333694458\n",
            "Entity Loss: 6.466029167175293\n",
            "Epoch: 40, Loss:  3.3347229957580566\n",
            "Generative Loss: 2.5288236141204834\n",
            "Entity Loss: 4.47476863861084\n",
            "Epoch: 40, Loss:  2.9180126190185547\n",
            "Generative Loss: 4.593890190124512\n",
            "Entity Loss: 7.300940990447998\n",
            "Epoch: 40, Loss:  5.135300636291504\n",
            "Generative Loss: 3.7678825855255127\n",
            "Entity Loss: 2.182450771331787\n",
            "Epoch: 40, Loss:  3.450796127319336\n",
            "Generative Loss: 4.752024173736572\n",
            "Entity Loss: 5.126307487487793\n",
            "Epoch: 40, Loss:  4.826880931854248\n",
            "Generative Loss: 1.3641870021820068\n",
            "Entity Loss: 5.6912055015563965\n",
            "Epoch: 41, Loss:  2.229590892791748\n",
            "Generative Loss: 2.624647378921509\n",
            "Entity Loss: 4.016101837158203\n",
            "Epoch: 41, Loss:  2.9029383659362793\n",
            "Generative Loss: 4.040231227874756\n",
            "Entity Loss: 3.6922125816345215\n",
            "Epoch: 41, Loss:  3.970627784729004\n",
            "Generative Loss: 3.248737335205078\n",
            "Entity Loss: 5.255882263183594\n",
            "Epoch: 41, Loss:  3.6501665115356445\n",
            "Generative Loss: 2.601663112640381\n",
            "Entity Loss: 6.050836086273193\n",
            "Epoch: 41, Loss:  3.2914977073669434\n",
            "Generative Loss: 3.2808353900909424\n",
            "Entity Loss: 3.3188095092773438\n",
            "Epoch: 41, Loss:  3.2884302139282227\n",
            "Generative Loss: 1.6209394931793213\n",
            "Entity Loss: 6.359974384307861\n",
            "Epoch: 41, Loss:  2.568746566772461\n",
            "Generative Loss: 2.792355537414551\n",
            "Entity Loss: 3.668529987335205\n",
            "Epoch: 42, Loss:  2.967590570449829\n",
            "Generative Loss: 5.459864139556885\n",
            "Entity Loss: 2.192901849746704\n",
            "Epoch: 42, Loss:  4.806471824645996\n",
            "Generative Loss: 3.8634493350982666\n",
            "Entity Loss: 5.557371616363525\n",
            "Epoch: 42, Loss:  4.202233791351318\n",
            "Generative Loss: 2.673912286758423\n",
            "Entity Loss: 6.510706901550293\n",
            "Epoch: 42, Loss:  3.4412713050842285\n",
            "Generative Loss: 5.242605209350586\n",
            "Entity Loss: 6.472535610198975\n",
            "Epoch: 42, Loss:  5.488591194152832\n",
            "Generative Loss: 4.295938014984131\n",
            "Entity Loss: 6.385788440704346\n",
            "Epoch: 42, Loss:  4.7139081954956055\n",
            "Generative Loss: 1.7561986446380615\n",
            "Entity Loss: 5.786516189575195\n",
            "Epoch: 42, Loss:  2.5622620582580566\n",
            "Generative Loss: 1.7820966243743896\n",
            "Entity Loss: 7.076120853424072\n",
            "Epoch: 43, Loss:  2.8409013748168945\n",
            "Generative Loss: 2.5477826595306396\n",
            "Entity Loss: 2.55265736579895\n",
            "Epoch: 43, Loss:  2.548757553100586\n",
            "Generative Loss: 1.6304413080215454\n",
            "Entity Loss: 2.933213233947754\n",
            "Epoch: 43, Loss:  1.890995740890503\n",
            "Generative Loss: 3.4528841972351074\n",
            "Entity Loss: 5.131007671356201\n",
            "Epoch: 43, Loss:  3.788508892059326\n",
            "Generative Loss: 1.8305119276046753\n",
            "Entity Loss: 4.608426094055176\n",
            "Epoch: 43, Loss:  2.386094808578491\n",
            "Generative Loss: 4.7247796058654785\n",
            "Entity Loss: 5.317790985107422\n",
            "Epoch: 43, Loss:  4.843381881713867\n",
            "Generative Loss: 2.0643162727355957\n",
            "Entity Loss: 0.0\n",
            "Epoch: 43, Loss:  1.6514530181884766\n",
            "Generative Loss: 1.408223032951355\n",
            "Entity Loss: 2.996330738067627\n",
            "Epoch: 44, Loss:  1.7258446216583252\n",
            "Generative Loss: 1.6155281066894531\n",
            "Entity Loss: 3.081939458847046\n",
            "Epoch: 44, Loss:  1.9088103771209717\n",
            "Generative Loss: 4.2637457847595215\n",
            "Entity Loss: 3.0322372913360596\n",
            "Epoch: 44, Loss:  4.017444133758545\n",
            "Generative Loss: 3.1605875492095947\n",
            "Entity Loss: 3.2709438800811768\n",
            "Epoch: 44, Loss:  3.1826589107513428\n",
            "Generative Loss: 2.417372465133667\n",
            "Entity Loss: 4.534034729003906\n",
            "Epoch: 44, Loss:  2.840704917907715\n",
            "Generative Loss: 3.536712884902954\n",
            "Entity Loss: 2.7131242752075195\n",
            "Epoch: 44, Loss:  3.371995210647583\n",
            "Generative Loss: 3.2732887268066406\n",
            "Entity Loss: 4.064416408538818\n",
            "Epoch: 44, Loss:  3.4315145015716553\n",
            "Generative Loss: 2.0814335346221924\n",
            "Entity Loss: 7.850465297698975\n",
            "Epoch: 45, Loss:  3.2352399826049805\n",
            "Generative Loss: 5.404191017150879\n",
            "Entity Loss: 1.8344786167144775\n",
            "Epoch: 45, Loss:  4.690248489379883\n",
            "Generative Loss: 2.3294413089752197\n",
            "Entity Loss: 5.508388042449951\n",
            "Epoch: 45, Loss:  2.965230703353882\n",
            "Generative Loss: 4.716290473937988\n",
            "Entity Loss: 3.3992934226989746\n",
            "Epoch: 45, Loss:  4.4528913497924805\n",
            "Generative Loss: 3.6127288341522217\n",
            "Entity Loss: 6.633713722229004\n",
            "Epoch: 45, Loss:  4.216926097869873\n",
            "Generative Loss: 1.6358038187026978\n",
            "Entity Loss: 5.504434108734131\n",
            "Epoch: 45, Loss:  2.4095299243927\n",
            "Generative Loss: 3.435408115386963\n",
            "Entity Loss: 2.6671738624572754\n",
            "Epoch: 45, Loss:  3.281761407852173\n",
            "Generative Loss: 2.240028142929077\n",
            "Entity Loss: 5.098155498504639\n",
            "Epoch: 46, Loss:  2.8116536140441895\n",
            "Generative Loss: 1.809929609298706\n",
            "Entity Loss: 3.007018804550171\n",
            "Epoch: 46, Loss:  2.049347400665283\n",
            "Generative Loss: 2.2279579639434814\n",
            "Entity Loss: 3.7304794788360596\n",
            "Epoch: 46, Loss:  2.5284624099731445\n",
            "Generative Loss: 1.2712708711624146\n",
            "Entity Loss: 6.082476615905762\n",
            "Epoch: 46, Loss:  2.2335121631622314\n",
            "Generative Loss: 4.756220817565918\n",
            "Entity Loss: 5.187585830688477\n",
            "Epoch: 46, Loss:  4.842494010925293\n",
            "Generative Loss: 4.133497714996338\n",
            "Entity Loss: 5.613188743591309\n",
            "Epoch: 46, Loss:  4.429435729980469\n",
            "Generative Loss: 5.386972427368164\n",
            "Entity Loss: 6.650423049926758\n",
            "Epoch: 46, Loss:  5.639662742614746\n",
            "Generative Loss: 4.172390937805176\n",
            "Entity Loss: 0.0\n",
            "Epoch: 47, Loss:  3.3379127979278564\n",
            "Generative Loss: 3.2982397079467773\n",
            "Entity Loss: 4.151421070098877\n",
            "Epoch: 47, Loss:  3.4688758850097656\n",
            "Generative Loss: 1.2235724925994873\n",
            "Entity Loss: 4.3924174308776855\n",
            "Epoch: 47, Loss:  1.8573415279388428\n",
            "Generative Loss: 2.0433056354522705\n",
            "Entity Loss: 7.242454528808594\n",
            "Epoch: 47, Loss:  3.0831356048583984\n",
            "Generative Loss: 2.9919331073760986\n",
            "Entity Loss: 6.372987270355225\n",
            "Epoch: 47, Loss:  3.6681442260742188\n",
            "Generative Loss: 1.855711817741394\n",
            "Entity Loss: 2.6295621395111084\n",
            "Epoch: 47, Loss:  2.010481834411621\n",
            "Generative Loss: 2.30597186088562\n",
            "Entity Loss: 3.1051082611083984\n",
            "Epoch: 47, Loss:  2.46579909324646\n",
            "Generative Loss: 2.1821811199188232\n",
            "Entity Loss: 3.283740520477295\n",
            "Epoch: 48, Loss:  2.4024930000305176\n",
            "Generative Loss: 4.018181800842285\n",
            "Entity Loss: 7.76163387298584\n",
            "Epoch: 48, Loss:  4.766872406005859\n",
            "Generative Loss: 2.090481996536255\n",
            "Entity Loss: 6.450562953948975\n",
            "Epoch: 48, Loss:  2.962498188018799\n",
            "Generative Loss: 2.219460964202881\n",
            "Entity Loss: 4.58643102645874\n",
            "Epoch: 48, Loss:  2.6928551197052\n",
            "Generative Loss: 4.438027381896973\n",
            "Entity Loss: 3.628913640975952\n",
            "Epoch: 48, Loss:  4.276204586029053\n",
            "Generative Loss: 2.30126953125\n",
            "Entity Loss: 0.0\n",
            "Epoch: 48, Loss:  1.8410156965255737\n",
            "Generative Loss: 3.0309481620788574\n",
            "Entity Loss: 5.510984420776367\n",
            "Epoch: 48, Loss:  3.5269556045532227\n",
            "Generative Loss: 3.9277238845825195\n",
            "Entity Loss: 4.283539772033691\n",
            "Epoch: 49, Loss:  3.998887300491333\n",
            "Generative Loss: 4.566760063171387\n",
            "Entity Loss: 1.6276874542236328\n",
            "Epoch: 49, Loss:  3.97894549369812\n",
            "Generative Loss: 4.221350193023682\n",
            "Entity Loss: 1.065332293510437\n",
            "Epoch: 49, Loss:  3.590146541595459\n",
            "Generative Loss: 1.8018158674240112\n",
            "Entity Loss: 5.41306209564209\n",
            "Epoch: 49, Loss:  2.5240650177001953\n",
            "Generative Loss: 3.2239840030670166\n",
            "Entity Loss: 3.1643612384796143\n",
            "Epoch: 49, Loss:  3.212059497833252\n",
            "Generative Loss: 5.2455644607543945\n",
            "Entity Loss: 3.5932223796844482\n",
            "Epoch: 49, Loss:  4.915096282958984\n",
            "Generative Loss: 6.400229454040527\n",
            "Entity Loss: 2.10341477394104\n",
            "Epoch: 49, Loss:  5.540866374969482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqDzYgwqX3Ee"
      },
      "source": [
        "### Loading entire model from the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfF80XCt_Xom"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model_name = \"T5\"\n",
        "model_type = \"w_named_entities\"\n",
        "data_name = \"heart-failure\"\n",
        "\n",
        "# model path\n",
        "MODEL_DIRECTORY_PATH = f\"{data_name}-FINAL-CHECKPTS/{model_name}\"\n",
        "model_path = f\"{MODEL_DIRECTORY_PATH}/{model_name}-{model_type}.pt\"\n",
        "\n",
        "#model = model.load_state_dict(torch.load(model_path))\n",
        "model = torch.load(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgZIpUjRDPtg"
      },
      "source": [
        "### Experiment with generating summaries. Note that during inference, we shall experiment with the different input configurations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import scispacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "from pprint import pprint\n",
        "import os\n",
        "\n",
        "from spacy import displacy\n",
        "import en_core_sci_sm\n",
        "from scispacy.abbreviation import AbbreviationDetector\n",
        "from scispacy.linking import EntityLinker"
      ],
      "metadata": {
        "id": "FWnyspP0hQIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBjt3_wamn8z"
      },
      "source": [
        "def _loadModel(model_name, model_path):\n",
        "  if model_name == 'BART':\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "  elif model_name == 'T5':\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "  elif model_name == \"Pegasus\":\n",
        "    model = PegasusForConditionalGeneration.from_pretrained(model_path)\n",
        "    tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "\n",
        "  return model, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO4QjVuwOLnK"
      },
      "source": [
        "def _generate_abstractive_summary(input_text, model, tokenizer, MAX_LEN=250):\n",
        "  inputs = tokenizer(input_text, truncation=True, padding='longest',return_tensors='pt').to(device)\n",
        "  # Get the highest-scoring beam as the abstractive summary\n",
        "  summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=70, max_length=MAX_LEN, \n",
        "                               early_stopping=True, num_return_sequences=1)\n",
        "  \n",
        "  tgt_text = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
        "  abstractive_summary = tgt_text[0]\n",
        "\n",
        "  return abstractive_summary\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install stanza to run NER on the generated summaries"
      ],
      "metadata": {
        "id": "cEE7UubOutfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q git+https://github.com/stanfordnlp/stanza.git"
      ],
      "metadata": {
        "id": "N_0A_cCKurw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "\n",
        "def _extract_named_entities(clinical_note, i2b2_model):\n",
        "  lst_entities = []\n",
        "\n",
        "  doc_i2b2 = i2b2_model(clinical_note)\n",
        "  for ent in doc_i2b2.entities:\n",
        "    lst_entities.append(ent.text)\n",
        "  \n",
        "  lst_entities = list(set(lst_entities))\n",
        "  str_entities = \" | \".join(lst_entities)\n",
        "  \n",
        "  return str_entities"
      ],
      "metadata": {
        "id": "caOCTzejugwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tQ7H5aBO6bG"
      },
      "source": [
        "def main():\n",
        "  lst_modelName = [\"T5\", \"BART\", \"Pegasus\"]\n",
        "  lst_model_type = [\"vanilla\", \"w_named_entities\"]\n",
        "  #data_name = \"heart-failure\"\n",
        "  data_name = \"NLMCXR_reports_ecgen_radiology\"\n",
        "\n",
        "  inference_type = \"vanilla\"   # determines what to pass during model inference time (testing time)\n",
        "\n",
        "  # download and initialize a mimic pipeline with an i2b2 NER model\n",
        "  stanza.download('en', package='mimic', processors={'ner': 'i2b2'})\n",
        "  nlp_i2b2 = stanza.Pipeline('en', package='mimic', processors={'ner': 'i2b2'})\n",
        "\n",
        "  for modelName in lst_modelName:\n",
        "    for model_type in lst_model_type:\n",
        "\n",
        "      input_fileName = f\"{data_name}_w_named_entities.jsonl\"\n",
        "      output_filename = f\"{data_name}-summaries-{model_type}.jsonl\"\n",
        "\n",
        "      # model path\n",
        "      MODEL_DIRECTORY_PATH = f\"{data_name}-FINAL-CHECKPTS/{modelName}\" \n",
        "      model_path = f'{MODEL_DIRECTORY_PATH}/{modelName}-{model_type}-checkpoints/'   # this is checkpoint path in other words\n",
        "\n",
        "      model, tokenizer = _loadModel(modelName, model_path)\n",
        "      model = model.to(device)\n",
        "\n",
        "\n",
        "      SUMMARY_OUTPUT_PATH = f\"{data_name}-FINAL-SUMMARIES_w_named_entites_at_inference/{modelName}\"\n",
        "      os.makedirs(SUMMARY_OUTPUT_PATH, exist_ok=True)\n",
        "      \n",
        "      with open(f\"{input_fileName}\") as f:\n",
        "        \n",
        "        for idx, line in enumerate(f):\n",
        "          if idx % 1000 == 0:\n",
        "            print(\"Iteration: \", idx)\n",
        "          dict_data = json.loads(line)\n",
        "          \n",
        "          if inference_type == \"w_named_entities\":\n",
        "            input_text = dict_data['finding_named_entities'] + \" [SEP] \" + dict_data['finding']\n",
        "          else:\n",
        "            input_text = dict_data['finding']  # this is the vanilla input configuration at inference time (i.e., without named entities)\n",
        "          summary = _generate_abstractive_summary(input_text, model, tokenizer)\n",
        "\n",
        "          summary_named_entities = _get_named_entities(summary, nlp_i2b2)  # named entities for the generated summary\n",
        "\n",
        "          dict_1 = {\"finding\" : dict_data['finding'],\n",
        "                    \"impression\" : dict_data['impression'],\n",
        "                    \"finding_named_entities\" : dict_data['finding_named_entities'],\n",
        "                    \"impression_named_entities\" : dict_data['impression_named_entities'],\n",
        "                    \"abstractive_summary\" : summary,\n",
        "                    \"abstractive_summary_named_entities\" : summary_named_entities\n",
        "                    }\n",
        "              \n",
        "          with jsonlines.open(f\"{SUMMARY_OUTPUT_PATH}/{output_filename}\", \"a\") as writer:\n",
        "            writer.write(dict_1)\n",
        "          writer.close()\n",
        "          \n",
        "      f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzrOm9IVOLlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3e591b-b791-4e0f-9630-574407ec47af"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y10HFUrdilpV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}